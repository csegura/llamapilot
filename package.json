{
  "name": "llamapilot",
  "displayName": "llamaPilot: write and improve code using your own AI",
  "description": "Extension that allows you to use your own llama.cpp provider",
  "version": "0.0.1",
  "publisher": "csegura",
  "icon": "resources/icon.png",
  "license": "MIT",
  "repository": {
    "url": "https://github.com/timkmecl/llamaPilot-vscode"
  },
  "engines": {
    "vscode": "^1.80.0"
  },
  "categories": [
    "Other"
  ],
  "keywords": [
    "copilot",
    "openai",
    "llamaPilot",
    "ai",
    "explain",
    "find bugs",
    "explain ",
    "refactor"
  ],
  "main": "./dist/extension.js",
  "activationEvents": [],
  "contributes": {
    "commands": [
      {
        "command": "llamaPilot.ask",
        "title": "Ask llamaPilot"
      },
      {
        "command": "llamaPilot.explain",
        "title": "llamaPilot: Explain selection"
      },
      {
        "command": "llamaPilot.refactor",
        "title": "llamaPilot: Refactor selection"
      },
      {
        "command": "llamaPilot.findProblems",
        "title": "llamaPilot: Find problems"
      },
      {
        "command": "llamaPilot.optimize",
        "title": "llamaPilot: Optimize selection"
      },
      {
        "command": "llamaPilot.conversationId",
        "title": "Set llamaPilot conversation ID"
      },
      {
        "command": "llamaPilot.resetConversation",
        "title": "Reset llamaPilot conversation"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "command": "llamaPilot.ask",
          "when": "editorTextFocus",
          "group": "llamaPilot-menu-group@1"
        },
        {
          "command": "llamaPilot.explain",
          "when": "editorHasSelection",
          "group": "llamaPilot-menu-group@2"
        },
        {
          "command": "llamaPilot.refactor",
          "when": "editorHasSelection",
          "group": "llamaPilot-menu-group@3"
        },
        {
          "command": "llamaPilot.findProblems",
          "when": "editorHasSelection",
          "group": "llamaPilot-menu-group@4"
        },
        {
          "command": "llamaPilot.optimize",
          "when": "editorHasSelection",
          "group": "llamaPilot-menu-group@5"
        }
      ],
      "commandPalette": [
        {
          "command": "llamaPilot.ask"
        },
        {
          "command": "llamaPilot.explain",
          "when": "editorHasSelection"
        },
        {
          "command": "llamaPilot.refactor",
          "when": "editorHasSelection"
        },
        {
          "command": "llamaPilot.findProblems",
          "when": "editorHasSelection"
        },
        {
          "command": "llamaPilot.optimize",
          "when": "editorHasSelection"
        },
        {
          "command": "llamaPilot.conversationId"
        },
        {
          "command": "llamaPilot.resetConversation"
        }
      ]
    },
    "viewsContainers": {
      "activitybar": [
        {
          "id": "llamaPilot",
          "title": "llamaPilot",
          "icon": "resources/llamapilot.png"
        }
      ]
    },
    "views": {
      "llamaPilot": [
        {
          "type": "webview",
          "id": "llamaPilot.chatView",
          "name": "llamaPilot"
        }
      ]
    },
    "configuration": {
      "title": "llamaPilot",
      "type": "object",
      "properties": {
        "llamaPilot.url": {
          "type": "string",
          "description": "Url Llama.cpp api",
          "order": 1,
          "value": "http://192.168.11.211:8000/v1"
        },
        "llamaPilot.pasteOnClick": {
          "type": "boolean",
          "default": true,
          "description": "Paste the code from a codeblock inside the response into the editor when you click on it",
          "order": 2
        },
        "llamaPilot.promptPrefix.explain": {
          "type": "string",
          "default": "Explain what this code does: ",
          "description": "The prompt prefix used for explaining the selected code",
          "order": 3
        },
        "llamaPilot.promptPrefix.refactor": {
          "type": "string",
          "default": "Refactor this code and explain what's changed: ",
          "description": "The prompt prefix used for refactoring the selected code",
          "order": 4
        },
        "llamaPilot.promptPrefix.findProblems": {
          "type": "string",
          "default": "Find problems with the following code, fix them and explain what was wrong (Do not change anything else): ",
          "description": "The prompt prefix used for finding problems in the selected code",
          "order": 5
        },
        "llamaPilot.promptPrefix.optimize": {
          "type": "string",
          "default": "Optimize the following code: ",
          "description": "The prompt prefix used for optimizing the selected code",
          "order": 6
        },
        "llamaPilot.keepConversation": {
          "type": "boolean",
          "default": true,
          "description": "Keep the conversation going by using the same conversation ID for all requests (allows follow-up questions)",
          "order": 7
        },
        "llamaPilot.timeoutLength": {
          "type": "number",
          "default": "60",
          "description": "How long should the request wait for a response before timing out (in seconds)",
          "order": 8
        },
        "llamaPilot.selectedInsideCodeblock": {
          "type": "boolean",
          "default": true,
          "description": "Append selected code as a codeblock (```...code...```) instead of plain text",
          "order": 9
        },
        "llamaPilot.max_tokens": {
          "type": "number",
          "default": "2500",
          "description": "llama.cpp: max_tokens parameter",
          "order": 10
        },
        "llamaPilot.temperature": {
          "type": "number",
          "default": "0.2",
          "description": "llama.cpp: temperature parameter",
          "order": 11
        },
        "llamaPilot.max_new_tokens": {
          "type": "number",
          "default": "200",
          "description": "llama.cpp: max_new_tokens parameter",
          "order": 12
        },
        "llamaPilot.top_k": {
          "type": "number",
          "default": "50",
          "description": "llama.cpp: top_k parameter",
          "order": 13
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run package_debug",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "webpack --mode production --devtool hidden-source-map",
    "package_debug": "webpack --mode development --devtool inline-source-map",
    "compile-tests": "tsc -p . --outDir out",
    "watch-tests": "tsc -p . -w --outDir out",
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js",
    "vsix": "vsce package"
  },
  "devDependencies": {
    "@types/glob": "^8.0.0",
    "@types/mocha": "^10.0.1",
    "@types/node": "16.x",
    "@types/vscode": "^1.73.0",
    "@typescript-eslint/eslint-plugin": "^5.45.0",
    "@typescript-eslint/parser": "^5.45.0",
    "@vscode/test-electron": "^2.2.0",
    "eslint": "^8.28.0",
    "glob": "^8.0.3",
    "mocha": "^10.1.0",
    "ts-loader": "^9.4.1",
    "typescript": "^4.9.3",
    "webpack": "^5.75.0",
    "webpack-cli": "^5.0.0"
  },
  "dependencies": {
    "node-fetch": "^3.3.2"
  }
}
